from pathlib import Path
from fdp.pdf import PDF, PageData
from fdp.drawer import draw_pdf_objects

THIS_DIR = Path(__file__).parent
DIR_TOOLS = THIS_DIR.joinpath('../tools')
DIR_DATA = THIS_DIR.joinpath('./data')

URL_PDF2TXT = 'https://raw.githubusercontent.com/pdfminer/pdfminer.six/master/tools/pdf2txt.py'
URL_PAPER = 'https://arxiv.org/pdf/1810.04805.pdf'

FN_PDF = DIR_DATA.joinpath('./1810.04805.pdf')
FN_TXT = DIR_DATA.joinpath('./1810.04805.txt')


def download_file(url, save_path):
    import urllib.request

    urllib.request.urlretrieve(url, save_path)


def check_tool_script():
    fn_script = DIR_TOOLS.joinpath('pdf2txt.py')
    if not fn_script.exists():
        print(
            'Script "pdfminer.six/pdf2txt.py" does not exist, it will be ' +
            f'downloaded into the following location now... :\n{fn_script.absolute()}'
        )
        download_file(URL_PDF2TXT, fn_script)


def check_data():
    if not FN_PDF.exists():
        import os

        print(
            'File "./data/1810.04805.pdf" does not exist, it will be ' +
            f'downloaded into the following location now... :\n{FN_PDF.absolute()}'
        )
        os.makedirs(DIR_DATA, exist_ok=True)
        download_file(URL_PAPER, FN_PDF.absolute())

    if not FN_TXT.exists():
        from subprocess import check_call
        import shlex

        print('Extracting text from PDF file using "pdf2txt.py"...')
        cmd = f'python ../tools/pdf2txt.py {FN_PDF.absolute()} -o {FN_TXT.absolute()}'
        check_call(shlex.split(cmd, posix=False), cwd=THIS_DIR)


def main():
    import json

    page_numbers = [0, 1, 2]
    pdf = PDF.load(str(FN_PDF), page_numbers=page_numbers)

    # Approach 01: Aggregate text according to existing parsed text (`raw_text`)
    # The reason why there is a need to analyze content with another text source
    # is that the string parser in `pdfminer.six` might failed to parse content
    # correctly. Hence that this approach give us a chance to extract text content
    # with the advantage of the layout algorithm provided by `pdfminer.six`, but
    # we can still replaced those matched text by our own source if we have a
    # better string parser.
    with open(FN_TXT, 'r', encoding='utf-8') as f:
        raw_text = f.read().splitlines()
    page_data_list1 = pdf.aggregate_raw_text(raw_text)

    with open('./output1.json', 'w') as f:
        json.dump([v.to_dict() for v in page_data_list1], f, indent=2)

    # Approach 02: Extract text using the result generated by layout algorithm
    # provided by in `pdfminer.six` directly
    page_data_list2 = []
    for page in pdf.pages:
        page_data = PageData.load_from_page(page)
        page_data_list2.append(page_data)

    with open('./output2.json', 'w') as f:
        json.dump([v.to_dict() for v in page_data_list2], f, indent=2)


if __name__ == '__main__':
    check_tool_script()
    check_data()
    main()
